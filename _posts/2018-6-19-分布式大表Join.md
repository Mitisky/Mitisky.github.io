---
layout: post
title:  "分布式大表Join计算"
date:   2018-6-19  +0800
categories: join
---



在分布式的场景下，join 操作一直是一个难题，因为 join 操作会涉及到大量是数据传输，势必导致 join 操作毕竟耗时。而网络资源也是分布式计算中非常重要的资源。从已有的 join 算法来看，如何减少网络负载是加快 join 的核心。*sort merge join*，*hash join*和*broadcast join*是目前常用的 join 方法。
这些算法适用于不同的场景，核心在用尽量减小数据传输，转而增加本地数据的计算量，这样能很大程度提高 join 的速度。但是对于行多列多的大表join，同时持久化 join 结果情况总是显得力不从心。
## 场景描述
需要对两张行和列都很多的表做 join ，并将 join 表持久化，生成一张中间表。下面用 A 表，B 表和 A-B 表来说明，其中A 表是10亿行200列的事实表，和 B 表是2亿行300列的维度表，A-B 为最终的left join 后的持久化表
## 解决方式
### 直接 join 
通过 spark sql 可以非常方便得进行 join 操作。spark sql默认是使用 sort merge join 算法进行两张表的 join操作。这种直接利用 spark sql 的方法，代码实现起来非常简单，但是带来的麻烦却不少。首先 A 表和 B 表的数据需要进行shuffle，容易造成 executor 的 OOM和心跳超时 。此外生成 join 表持久化到磁盘，会占用大量的磁盘空间。
### 索引方法一
为了解决直接 join 带来的两个问题，同时我们发现由于A-B 表是由于 A left join B 表得到的，那么 A-B 表中的 A 表部分的数据和 A 表自身是完全一样的。那么只需要将 A-B join 表中 B 表的数据，与 A 表原始数据进行对齐，那么可以省去存储 A-B 表中的 A 表数据。
首先需要给 A 增加一个索引或者叫标记列，不是真正意义上的索引，该列主要是为了使最后的A-B join 的顺序与 A 表原始数据对齐，这样就可以通过行号来将 A 表的原始数据和 A-B 表中 B 表数据进行关联。从而重复利用A 表的原始数据。同时再计算过程中， A 表只有索引和关联列两列参与 join 计算，shuffle 数据量大大减少。但是为了与 A 表对齐，在索引列上又进行了一次 shuffle。最终 A-B 表持久化的数据中，将不再把 A 表的数据存入，只需存储关联后 B 表的数据，同时与 A 表对齐即可。这是一个非常有效的方法，能够有效减少计算和持久化的数据量。该办法依然可以通过 spark sql 的 join 方法来实现，实现上稍微有些麻烦。
### 索引方法二
索引方法一中依然存在一个大的弊端。B 表的数据是全部参与 join 计算的，并且在关联后，是被全部持久化的。那么B 表很大的情况下，例如当前例子中的 B 表，2亿300列的数据，这依然是难以忽略的数据量。在做 join 计算和持久化的过程中，B 表的数据量会严重影响最后成功与否。依据上面增加索引列的方法，很容易想到将 B 表增加索引替代原始数据。这里的索引是真正意义上的索引，通过该索引来查找 B 表的数据。实现该方法并不复杂，而且无论速度还是数据量都有明显提高。可是，该方法并不实用。下面详细说一下该方法的问题
当数据在一台机器的情况下，该方法没有什么问题。但是如果数据分块，且分布在不同机器的时候。该办法就显得力不从心了。将设我们在某一个计算节点，该节点有着 A-B 表中的第一块数据。我们首先取出第一行数据，顺利拿到其中 B 表的索引。有了该索引，我们进而可以获得 B表这一行的数据。可问题就在这里，如果这一行数据是被存在集群中其它机器上的话怎么办呢？我们会将该行数据拉取到计算节点来，而分布式数据多是以块为单位，所以我们需要把包含第一行数据的全部数据块拉到本机来。那如果A-B 表第二行的索引指向的数据又在集群中某一台计算，我们又需要拉取一块过来。以此类推，计算节点可能会有着全部 B 表数据，而且无法丢弃，因为可能下一行很快就用到该块数据。实际情况是一台机器很难容的下这么大的数据，而且这么多数据都要走网络，耗时可想而知。虽然场景有点极端，但是这个情况基本宣判该办法的死亡
###  索引方法二改善
既然计算节点无法存的下这么多的数据，那么就想办法减少数据。按需取数同时按列取数是一个不错的办法。需要 A-B 中 B 那部份的某些字段，那么就只取这几个字段，而且按列计算的话，一列计算完成，就可以丢掉该列数据。由于是按需取数，那么必须知道分析用到哪些列。因此这个改善需要产品功能的支持才行。
### 最终方法
很不巧我们的产品觉得，生成关联时候让用户来指定计算列很不友好，而且分析过程中计算关联速度太慢，必须在生成关联表的时候得出全部数据。
因此，我们必须重新思考上述的全部问题。首先我们来梳理一下问题
* A,B表数据行多列多，而且A,B数据分布在不同的机器
* A-B表数据太多，而且 A-B表的 A 部分数据与 A 表原始数据相同，可以省去。
* shuffle 过程中数据量太多，内存压力大。而且为了不存 A 数据，需要进行第二次 shuffle